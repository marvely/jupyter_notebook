{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets('/tmp/data', one_hot = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.contrib.learn.python.learn.datasets.base.Datasets"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(mnist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(mnist.train.images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55000, 784)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.train.images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sample = mnist.train.images[1].reshape(28,28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x120a76e90>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD8CAYAAABXXhlaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1209dac90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(sample, cmap = 'Greys')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### build a multilayer perceptron to take in the pixel data and correctly classify what number it represents\n",
    "1. Learning rate is how quickly we adjust the cost function! How quickly do you want to apply the adam optimizer to the layer!\n",
    "2. Training epochs is how many training cycles this will go through...\n",
    "3. Batch size, the size of the batches of the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.001 # <-- the lower the rate, the higher the possibility for accurate training result??!!\n",
    "# but it will take longer to run if the rate is lower~\n",
    "training_epochs = 15\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_classes = 10\n",
    "n_samples = mnist.train.num_examples\n",
    "n_input = 784 # the input is the flatten version of the array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55000"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The number of neurons we use in the two layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_hidden_1 = 256\n",
    "n_hidden_2 = 256"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Process breakdown ####\n",
    "1. We will take the input and send them to the first hidden layer\n",
    "2. The data will have a weight attached to it after it went through the first hidden layer\n",
    "3. Add a bias along with that\n",
    "4. Continue the same step 2 and 3 in the hidden layer 2.\n",
    "5. Finally we will have the output layer\n",
    "6. Evaluate the model performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### loss function, cost function <-- apply an optimization to the cost, lower the rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# adam optimizer is the most common one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def multilayer_perceptron(x, weights, biases):\n",
    "    '''\n",
    "    x: data input\n",
    "    weights: a dictionary containing weights\n",
    "    biases: a dictionary containing biases\n",
    "    '''\n",
    "    layer_1 = tf.add(tf.matmul(x, weights['h1']), biases['b1'])\n",
    "    # doing matrix multiplication between the input and the first layer weights\n",
    "    # doing this using tf objects\n",
    "    # past the whole thing into the function, the rectifier function\n",
    "    layer_1 = tf.nn.relu(layer_1)\n",
    "    \n",
    "    # do the same thing to layer 2\n",
    "    layer_2 = tf.add(tf.matmul(layer_1, weights['h2']), biases['b2'])\n",
    "    layer_2 = tf.nn.relu(layer_2)\n",
    "    \n",
    "    # last output layer\n",
    "    out_layer = tf.matmul(layer_2, weights['out']) + biases['out']\n",
    "    \n",
    "    return out_layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order for tf to work, we will need to create two tf objects: tf variables as weights and biases to feed the multilayer perceptron.\n",
    "A variable is a modifiable tensor lives in the tf graph computation...?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "weights = {\n",
    "    'h1': tf.Variable(tf.random_normal([n_input, n_hidden_1])), # 784 rows, 256 col, thus can multiply with the x input (which has the length of 784)\n",
    "    'h2': tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2])), # the shape changes since we got the result from first layer is 256, thus here we will use 256 rows * 256 cols Matrix\n",
    "    'out': tf.Variable(tf.random_normal([n_hidden_2, n_classes])) # the output from layer 2 is 256, thus multiply by the matrix with 256 rows and 10 cols to make the final output be a vector length of 10.\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "biases = {\n",
    "    'b1': tf.Variable(tf.random_normal([n_hidden_1])),\n",
    "    'b2':tf.Variable(tf.random_normal([n_hidden_2])),\n",
    "    'out': tf.Variable(tf.random_normal([n_classes]))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finally create 2 placeholders for x and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder('float', [None, n_input])  # the shape of the input matrix is None*784"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = tf.placeholder('float', [None, n_classes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = multilayer_perceptron(x, weights, biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.framework.ops.Tensor"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next thing is to define Cost Optimization Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(pred, y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.contrib.learn.python.learn.datasets.base.Datasets"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(mnist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t = mnist.train.next_batch(1) #<- a tuple containing samples and the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xsamp, ysamp = t # x is the sample array, y is the output array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ysamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 784)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xsamp.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the Model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. initialize the variables created by us"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, cost190.5091\n",
      "Epoch: 2, cost43.5501\n",
      "Epoch: 3, cost27.4293\n",
      "Epoch: 4, cost19.3924\n",
      "Epoch: 5, cost13.8917\n",
      "Epoch: 6, cost10.3845\n",
      "Epoch: 7, cost7.8271\n",
      "Epoch: 8, cost5.9339\n",
      "Epoch: 9, cost4.2931\n",
      "Epoch: 10, cost3.3925\n",
      "Epoch: 11, cost2.5056\n",
      "Epoch: 12, cost2.0139\n",
      "Epoch: 13, cost1.5718\n",
      "Epoch: 14, cost1.1658\n",
      "Epoch: 15, cost0.9135\n",
      "Model has completed 15 Epochs of training\n"
     ]
    }
   ],
   "source": [
    "# 15 loops\n",
    "for epoch in range(training_epochs):\n",
    "    \n",
    "    # cost\n",
    "    avg_cost = 0.0\n",
    "    \n",
    "    total_batch = int(n_samples/ batch_size) # how many batches we will do when we use that sample size...\n",
    "    \n",
    "    for i in range(total_batch):\n",
    "        \n",
    "        batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "        \n",
    "        _, c = sess.run([optimizer, cost], feed_dict= {x: batch_x, y: batch_y})\n",
    "        \n",
    "        avg_cost += c / total_batch\n",
    "        \n",
    "    print  'Epoch: {}, cost{:.4f}'.format(epoch+1, avg_cost)\n",
    "    \n",
    "print 'Model has completed {} Epochs of training'.format(training_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF Built-in Model Evaluation Functions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "correct_pred = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "correct_pred = tf.cast(correct_pred, 'float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Cast_1:0\", shape=(?,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print correct_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "accuracy  = tf.reduce_mean(correct_pred) # need tf own methods to deal with tensor objects to get the mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Mean_1:0\", shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print accuracy #<-- still a tensor object..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'ArgMax_2:0' shape=() dtype=int64>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.argmax(mnist.test.labels[0], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mnist.test.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.45490199,  0.49019611,  0.67058825,  1.        ,  1.        ,\n",
       "         0.58823532,  0.36470589,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.66274512,\n",
       "         0.99215692,  0.99215692,  0.99215692,  0.99215692,  0.99215692,\n",
       "         0.99215692,  0.85490203,  0.11764707,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.66274512,  0.99215692,\n",
       "         0.99215692,  0.99215692,  0.83529419,  0.55686277,  0.6901961 ,\n",
       "         0.99215692,  0.99215692,  0.4784314 ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.20392159,  0.98039222,  0.99215692,\n",
       "         0.82352948,  0.1254902 ,  0.04705883,  0.        ,  0.02352941,\n",
       "         0.80784321,  0.99215692,  0.54901963,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.3019608 ,  0.98431379,  0.82352948,\n",
       "         0.09803922,  0.        ,  0.        ,  0.        ,  0.4784314 ,\n",
       "         0.97254908,  0.99215692,  0.25490198,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.12156864,  0.07058824,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.81960791,\n",
       "         0.99215692,  0.99215692,  0.25490198,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.45882356,  0.96862751,\n",
       "         0.99215692,  0.77647066,  0.03921569,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.29803923,  0.96862751,  0.99215692,\n",
       "         0.90588242,  0.24705884,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.50196081,  0.99215692,  0.99215692,\n",
       "         0.56470591,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.6901961 ,  0.96470594,  0.99215692,  0.62352943,\n",
       "         0.04705883,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.09803922,  0.91764712,  0.99215692,  0.91372555,  0.13725491,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.77647066,  0.99215692,  0.99215692,  0.5529412 ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.30588236,\n",
       "         0.97254908,  0.99215692,  0.74117649,  0.04705883,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.07450981,  0.7843138 ,\n",
       "         0.99215692,  0.99215692,  0.5529412 ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.52549022,  0.99215692,\n",
       "         0.99215692,  0.67843139,  0.04705883,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.97254908,  0.99215692,\n",
       "         0.99215692,  0.09803922,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.97254908,  0.99215692,\n",
       "         0.99215692,  0.16862746,  0.07843138,  0.07843138,  0.07843138,\n",
       "         0.07843138,  0.01960784,  0.        ,  0.01960784,  0.07843138,\n",
       "         0.07843138,  0.14509805,  0.58823532,  0.58823532,  0.58823532,\n",
       "         0.57647061,  0.03921569,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.97254908,  0.99215692,\n",
       "         0.99215692,  0.99215692,  0.99215692,  0.99215692,  0.99215692,\n",
       "         0.99215692,  0.65882355,  0.56078434,  0.65098041,  0.99215692,\n",
       "         0.99215692,  0.99215692,  0.99215692,  0.99215692,  0.99215692,\n",
       "         0.99215692,  0.48235297,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.68235296,  0.99215692,\n",
       "         0.99215692,  0.99215692,  0.99215692,  0.99215692,  0.99215692,\n",
       "         0.99215692,  0.99215692,  0.99215692,  0.99215692,  0.99215692,\n",
       "         0.97647065,  0.96862751,  0.96862751,  0.66274512,  0.45882356,\n",
       "         0.45882356,  0.22352943,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.46274513,\n",
       "         0.48235297,  0.48235297,  0.48235297,  0.65098041,  0.99215692,\n",
       "         0.99215692,  0.99215692,  0.60784316,  0.48235297,  0.48235297,\n",
       "         0.16078432,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ]], dtype=float32)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.test.images[1].reshape(28, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9443"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy.eval(feed_dict= {\n",
    "        x: mnist.test.images,\n",
    "        y: mnist.test.labels\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### code used to generate multilayer perceptron in the exercise\n",
    "key points: \n",
    "1. transform the y_train and y_test to the one-hot encoding format 2D array\n",
    "2. without the convenient way to do next_batch(), grab the batches using for-loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# y_train[ :batch_size] #<-- this is not what we want... we want the one_hot coding!\n",
    "# how to transform y_train to a 2d array?? cols are two classes\n",
    "# y_train.shape\n",
    "y_train_transform = np.zeros((y_train.shape[0], 2))\n",
    "y_train_transform[np.arange(y_train.shape[0]), y_train] = 1\n",
    "# y_train_transform.shape\n",
    "\n",
    "# need to do the same to y_test.\n",
    "y_test_transform = np.zeros((len(y_test), 2))\n",
    "y_test_transform[np.arange(len(y_test)), y_test] = 1\n",
    "# y_test_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for epoch in range(training_epochs):\n",
    "    # cost\n",
    "    avg_cost = 0.0\n",
    "    \n",
    "    total_batch = int(n_samples / batch_size)\n",
    "    \n",
    "    for i in range(total_batch):\n",
    "        \n",
    "        batch_x = X_train[batch_size*i:(batch_size*(i + 1))]\n",
    "        batch_y = y_train_transform[batch_size*i:(batch_size*(i + 1))]\n",
    "        \n",
    "        _, c = sess.run([optimizer, cost], feed_dict={x: batch_x, y:batch_y})\n",
    "        \n",
    "        avg_cost += c / total_batch\n",
    "        \n",
    "    print 'Epoch: {}, cost: {:.4f}'.format(epoch + 1, avg_cost)\n",
    "    \n",
    "print 'Model has completed {} Epochs of training'.format(training_epochs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
